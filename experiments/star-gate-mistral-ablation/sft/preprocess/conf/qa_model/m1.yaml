model_type: vllm
name: mistral-m1-vllm
shortname: m1

model_config:
  model: /scr/andukuri/assistant-gate-hgx/finetuned_models/star-2-mistral-ablation/m1/final
  download_dir: /scr/andukuri/assistant-gate-hgx/finetuned_models/star-2-mistral-ablation/m1/final
  dtype: auto
  tensor_parallel_size: 2
  seed: 1

tokenizer_config:
  pretrained_model_name_or_path: mistralai/Mistral-7B-Instruct-v0.2
  cache_dir: /scr/andukuri/assistant-gate-hgx/pretrained_models/Mistral-7B-Instruct-v0.2
  model_max_length: 1024

run:
  batch_size: 750
  verbose: false
  completion_config:
    do_sample: false
    best_of: 1
    temperature: 0.0
    top_p: 1
    top_k: -1
    max_new_tokens: 700
    use_beam_search: false
    presence_penalty: 0
    frequency_penalty: 0
    num_return_sequences: 1
