rating_model:
  hydra:
    run:
      dir: outputs
  model_type: openai
  name: gpt4
  model_config:
    azure_api:
      azure_endpoint: https://philipp.openai.azure.com/
      api_version: '2024-02-01'
    seed: 1
  run:
    verbose: false
    completion_config:
      model: gpt-4
      max_tokens: 300
      temperature: 0
      top_p: 0.9
      'n': 1
answer_model:
  hydra:
    run:
      dir: outputs
  model_type: vllm
  name: llama3-m3-vllm
  shortname: m3
  model_config:
    model: /scr/andukuri/assistant-gate-hgx/finetuned_models/star-gate-llama3/m3/final
    download_dir: /scr/andukuri/assistant-gate-hgx/finetuned_models/star-gate-llama3/m3/final
    dtype: auto
    tensor_parallel_size: 8
    seed: 1
  run:
    batch_size: 50
    verbose: false
    completion_config:
      do_sample: false
      best_of: 1
      temperature: 0.0
      top_p: 1
      top_k: -1
      max_new_tokens: 700
      use_beam_search: false
      presence_penalty: 0
      frequency_penalty: 0
      num_return_sequences: 1
qa_model:
  hydra:
    run:
      dir: outputs
  model_type: vllm
  name: llama3-m3-vllm
  shortname: m3
  model_config:
    model: /scr/andukuri/assistant-gate-hgx/finetuned_models/star-gate-llama3/m3/final
    download_dir: /scr/andukuri/assistant-gate-hgx/finetuned_models/star-gate-llama3/m3/final
    dtype: auto
    tensor_parallel_size: 2
    seed: 1
  tokenizer_config:
    pretrained_model_name_or_path: meta-llama/Meta-Llama-3-70B-Instruct
    cache_dir: /scr/andukuri/assistant-gate-hgx/pretrained_models
    model_max_length: 1152
  run:
    batch_size: 750
    verbose: false
    completion_config:
      do_sample: false
      best_of: 1
      temperature: 0.0
      top_p: 1
      top_k: -1
      max_new_tokens: 700
      use_beam_search: false
      presence_penalty: 0
      frequency_penalty: 0
      num_return_sequences: 1
qa_model_2:
  hydra:
    run:
      dir: outputs
  model_type: vllm
  name: llama3-m1-vllm
  shortname: m1
  model_config:
    model: /scr/andukuri/assistant-gate-hgx/finetuned_models/star-gate-llama3/m1/final
    download_dir: /scr/andukuri/assistant-gate-hgx/finetuned_models/star-gate-llama3/m1/final
    dtype: auto
    tensor_parallel_size: 2
    seed: 1
  run:
    batch_size: 750
    verbose: false
    completion_config:
      do_sample: false
      best_of: 1
      temperature: 0.0
      top_p: 1
      top_k: -1
      max_new_tokens: 700
      use_beam_search: false
      presence_penalty: 0
      frequency_penalty: 0
      num_return_sequences: 1
split:
  name: test
ROLES:
- user
- assistant
MAX_TURNS: 3
k: 1
'n': 300
N_ITER: 4
RATER_SYS_PROMPT_IDX: 0
RATER_MAIN_PROMPT_IDX: 0
