qa_model:
  model_type: vllm
  name: llama3-m0-vllm
  shortname: m0
  model_config:
    model: meta-llama/Meta-Llama-3-70B-Instruct
    download_dir: /scr/andukuri/assistant-gate-hgx/pretrained_models
    dtype: auto
    tensor_parallel_size: 8
    seed: 1
  tokenizer_config:
    pretrained_model_name_or_path: meta-llama/Meta-Llama-3-70B-Instruct
    cache_dir: /scr/andukuri/assistant-gate-hgx/pretrained_models
    model_max_length: 1152
  run:
    batch_size: 2000
    verbose: false
    initial_completion_config:
      do_sample: true
      temperature: 0.9
      top_p: 0.9
      max_new_tokens: 700
      num_return_sequences: 10
    completion_config:
      do_sample: true
      temperature: 0.9
      top_p: 0.9
      max_new_tokens: 700
      num_return_sequences: 1
human_model:
  hydra:
    run:
      dir: outputs
  model_type: vllm
  name: llama3-m0-vllm
  shortname: m0
  model_config:
    model: meta-llama/Meta-Llama-3-70B-Instruct
    download_dir: /scr/andukuri/assistant-gate-hgx/pretrained_models
    dtype: auto
    tensor_parallel_size: 8
    seed: 1
  tokenizer_config:
    pretrained_model_name_or_path: meta-llama/Meta-Llama-3-70B-Instruct
    cache_dir: /scr/andukuri/assistant-gate-hgx/pretrained_models
    model_max_length: 1152
  run:
    batch_size: 2000
    verbose: false
    completion_config:
      do_sample: false
      temperature: 0
      top_p: 0.9
      max_new_tokens: 700
      num_return_sequences: 1
split:
  name: A
turn:
  number: 1
MAX_TURNS: 3
QA_PROMPT_IDX: 13
HUMAN_SYS_PROMPT_IDX: 1
HUMAN_PROMPT_IDX: 4
