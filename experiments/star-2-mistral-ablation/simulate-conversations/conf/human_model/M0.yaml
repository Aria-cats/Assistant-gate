hydra:
  run:
    dir: outputs

model_type: vllm
name: mixtral-m0-vllm
shortname: m0

model_config:
  model: mistralai/Mixtral-8x7B-Instruct-v0.1
  download_dir: /scr/andukuri/assistant-gate-hgx/pretrained_models/Mixtral-8x7B-Instruct-v0.1
  dtype: auto
  tensor_parallel_size: 4
  seed: 1


run:
  batch_size: 750
  verbose: false
  completion_config:
    do_sample: false
    temperature: 0.0
    top_p: 0.9
    max_new_tokens: 700
    num_return_sequences: 1
